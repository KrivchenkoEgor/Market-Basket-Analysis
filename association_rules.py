# =============================================================================
# Market Basket Analysis (Анализ корзины покупок)
# Цель: выявить товары, которые часто покупаются вместе, 
# чтобы формировать кросс-продажи, комплекты (бандлы) и оптимизировать ассортимент.
# Используется алгоритм Apriori для генерации правил ассоциации.
# Результат сохраняется в файл association_rules_full.csv
# =============================================================================

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules


# -----------------------------------------------------------------------------
# ШАГ 1: Загрузка данных
# -----------------------------------------------------------------------------
# Оригинальный датасет Online Retail содержит символы фунта (£), 
# поэтому используем кодировку ISO-8859-1 (latin-1), а не UTF-8.
# -----------------------------------------------------------------------------
df = pd.read_csv("OnlineRetail.csv", encoding="ISO-8859-1")


# -----------------------------------------------------------------------------
# ШАГ 2: Очистка названий колонок
# -----------------------------------------------------------------------------
# Убираем возможные пробелы по краям в названиях полей (например, " InvoiceNo" → "InvoiceNo")
# Это критично для корректной работы последующих операций.
# -----------------------------------------------------------------------------
df.columns = df.columns.str.strip()


# -----------------------------------------------------------------------------
# ШАГ 3: Фильтрация данных (подготовка к анализу)
# -----------------------------------------------------------------------------
# Удаляем:
# - отменённые заказы (InvoiceNo начинается с 'C'),
# - возвраты (Quantity <= 0),
# - транзакции без идентификатора клиента (CustomerID is null).
# Только "чистые" продажи участвуют в анализе корзины.
# -----------------------------------------------------------------------------
df = df[~df["InvoiceNo"].astype(str).str.startswith("C")]
df = df[df["Quantity"] > 0]
df = df.dropna(subset=["CustomerID"])


# -----------------------------------------------------------------------------
# ШАГ 4: Формирование транзакций (корзин покупок)
# -----------------------------------------------------------------------------
# Группируем товары по уникальному номеру заказа (InvoiceNo).
# Каждая строка в результате — это список товаров (Description) в одном чеке.
# Пример: ["WHITE HANGING HEART T-LIGHT HOLDER", "GLASS STAR FROSTED T-LIGHT HOLDER"]
# -----------------------------------------------------------------------------
transactions = df.groupby("InvoiceNo")["Description"].apply(list).tolist()


# -----------------------------------------------------------------------------
# ШАГ 5: Преобразование в бинарную матрицу (one-hot encoding)
# -----------------------------------------------------------------------------
# TransactionEncoder создаёт матрицу, где:
# - строки = транзакции (заказы),
# - столбцы = уникальные товары,
# - значение = 1, если товар есть в заказе, иначе 0.
# Это стандартный формат для алгоритмов анализа корзины.
# -----------------------------------------------------------------------------
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_ary, columns=te.columns_)


# -----------------------------------------------------------------------------
# ШАГ 6: Поиск частых наборов товаров (Frequent Itemsets)
# -----------------------------------------------------------------------------
# Алгоритм Apriori находит все комбинации товаров, 
# которые встречаются в заказах не реже, чем min_support.
# min_support=0.01 означает: набор должен быть в ≥1% всех заказов.
# use_colnames=True сохраняет названия товаров (а не индексы) в результатах.
# -----------------------------------------------------------------------------
frequent_itemsets = apriori(df_encoded, min_support=0.01, use_colnames=True)


# -----------------------------------------------------------------------------
# ШАГ 7: Генерация правил ассоциации
# -----------------------------------------------------------------------------
# На основе частых наборов строятся правила вида: {X} → {Y}
# - metric="confidence": правило должно срабатывать минимум в 30% случаев,
# - lift > 1.0: оставляем только положительные ассоциации (товары притягиваются).
# Сортировка по lift (в убывании): самые сильные связи — вверху.
# -----------------------------------------------------------------------------
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.3)
rules = rules[rules["lift"] > 1.0]
rules = rules.sort_values(by="lift", ascending=False)


# -----------------------------------------------------------------------------
# ШАГ 8: Подготовка результата к экспорту
# -----------------------------------------------------------------------------
# Поля 'antecedents' и 'consequents' хранятся как frozenset.
# Преобразуем их в читаемую строку через запятую для удобства в Excel/BI.
# -----------------------------------------------------------------------------
rules["antecedents"] = rules["antecedents"].apply(lambda x: ', '.join(list(x)))
rules["consequents"] = rules["consequents"].apply(lambda x: ', '.join(list(x)))


# -----------------------------------------------------------------------------
# ШАГ 9: Сохранение топ-20 правил
# -----------------------------------------------------------------------------
# Экспортируем только ключевые метрики:
# - antecedents: "если купили..."
# - consequents: "...то купят"
# - support: доля заказов с обоими товарами
# - confidence: надёжность правила
# - lift: сила ассоциации (чем выше — тем сильнее связь)
# -----------------------------------------------------------------------------
output = rules[["antecedents", "consequents", "support", "confidence", "lift"]].head(20)
output.to_csv("association_rules_full.csv", index=False)

print("✅ Анализ корзины завершён. Топ-20 правил сохранены в 'association_rules_full.csv'")